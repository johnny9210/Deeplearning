{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"name":"Process.ipynb","provenance":[],"collapsed_sections":["XLD2Wh-JFmHq","SB479b3vFmHr","M3kNbo6_FmH1","mdssqw2xFmIQ","_9knRnd6FmIT","7UAV_LuxFmIU","DC89wPxVFmIa"]}},"cells":[{"cell_type":"markdown","metadata":{"id":"yxqy7WEFFmHU"},"source":["# Tensorflow Object Detection API\n","- Tensorflow Object Detection API는 TensorFlow를 이용해서 Object Detection 모델을 train하고 deploy하는 것을 쉽게 도와주는 오픈소스 프레임워크.\n","- https://github.com/tensorflow/models/tree/master/research/object_detection\n","- Tutorial: https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/"]},{"cell_type":"markdown","metadata":{"id":"xJ4r9OWhFmHd"},"source":["# Custom (Image) Data 구하기"]},{"cell_type":"markdown","metadata":{"id":"t_wiuh0WFmHe"},"source":["# Custom (Image) Data Labeling"]},{"cell_type":"markdown","metadata":{"id":"3RWHj-JxFmHf"},"source":["# 전단계\n","- 구글드라이브 연결\n","- raw_data의 데이터압축파일을 VM local에 압축 푼다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5tag0DTwKqMb","executionInfo":{"status":"ok","timestamp":1632874748722,"user_tz":-540,"elapsed":22475,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}},"outputId":"b439c1de-5c3a-4e82-e3f2-094ee42350a5"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A6hBEOE_FmHf","executionInfo":{"status":"ok","timestamp":1632874772328,"user_tz":-540,"elapsed":340,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}},"outputId":"b92b5896-56cb-49a6-8f5a-761448ecd7d5"},"source":["# 현재 디렉토리\n","!pwd"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","metadata":{"id":"S0z4cgB4FmHg","executionInfo":{"status":"ok","timestamp":1632874792122,"user_tz":-540,"elapsed":2236,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}}},"source":["# 압축풀기. zip파일=>unzip 명령어로 푼다. unzip 압축파일 -d 압축풀 디렉토리\n","!unzip -q /content/drive/MyDrive/object_detection_src/sign_language_letters/raw_data/american_sign_language_letters.zip  -d /content/images"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yDjXGaXpFmHh"},"source":["# Tensorflow Object Detection 2 API 설치\n","1. clone \n","    - `!git clone https://github.com/tensorflow/models.git`\n","1. PYTHONPATH 환경설정에 models/research 추가  \n","1. 필요 모듈 설치\n","    - `!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk`\n","    - `!pip install -qq Cython contextlib2 pillow lxml matplotlib pycocotools`\n","1. proto 파일 컴파일\n","    - models/research 경로로 이동\n","        - `%cd models/research`\n","    - `!protoc object_detection/protos/*.proto --python_out=.`\n","1. setup.py 를 이용해 필요한 모듈 추가 설치\n","    - setup.py를 현재 디렉토리로 카피\n","        - `!cp object_detection/packages/tf2/setup.py . `\n","    - 설치\n","        - `!python -m pip install . `\n","    - 설치 확인 - 아래 스크립트 실행시 오류 없이 실행되면 설치 잘 된 것임.\n","        - `!python object_detection/builders/model_builder_tf2_test.py`\n","1. 원래 디렉토리로 이동\n","    - `%cd ../..`        "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pXjma-57FmHi","executionInfo":{"status":"ok","timestamp":1632874838136,"user_tz":-540,"elapsed":22491,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}},"outputId":"17c0d1ca-d66a-4b50-88b1-04e178efce99"},"source":["# Tensorflow Object Detection API2 를 clone\n","!git clone https://github.com/tensorflow/models.git"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'models'...\n","remote: Enumerating objects: 63918, done.\u001b[K\n","remote: Counting objects: 100% (423/423), done.\u001b[K\n","remote: Compressing objects: 100% (183/183), done.\u001b[K\n","remote: Total 63918 (delta 252), reused 408 (delta 240), pack-reused 63495\u001b[K\n","Receiving objects: 100% (63918/63918), 574.98 MiB | 32.48 MiB/s, done.\n","Resolving deltas: 100% (44670/44670), done.\n"]}]},{"cell_type":"code","metadata":{"id":"nfUf6dAzFmHi","executionInfo":{"status":"ok","timestamp":1632874878958,"user_tz":-540,"elapsed":296,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}}},"source":["# 환경설정 - PYTHONPATH = models/research\n","import os\n","os.environ['PYTHONPATH'] += \":/content/models/research\""],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"OaxAExrKFmHj","executionInfo":{"status":"ok","timestamp":1632874920092,"user_tz":-540,"elapsed":321,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}},"outputId":"8e630076-8e92-44cd-a2ee-c34560fd08df"},"source":["os.environ['PYTHONPATH']"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/env/python:/content/models/research'"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XP4q2LnTFmHk","executionInfo":{"status":"ok","timestamp":1632875116257,"user_tz":-540,"elapsed":11357,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}},"outputId":"81b163a6-6e53-4bda-f29c-86bc75280ac5"},"source":["#3. 추가 필요모듈 설치\n","!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Selecting previously unselected package python-bs4.\n","(Reading database ... 155013 files and directories currently installed.)\n","Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n","Unpacking python-bs4 (4.6.0-1) ...\n","Selecting previously unselected package python-pkg-resources.\n","Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n","Unpacking python-pkg-resources (39.0.1-2) ...\n","Selecting previously unselected package python-chardet.\n","Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n","Unpacking python-chardet (3.0.4-1) ...\n","Selecting previously unselected package python-six.\n","Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n","Unpacking python-six (1.11.0-2) ...\n","Selecting previously unselected package python-webencodings.\n","Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n","Unpacking python-webencodings (0.5-2) ...\n","Selecting previously unselected package python-html5lib.\n","Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n","Unpacking python-html5lib (0.999999999-1) ...\n","Selecting previously unselected package python-lxml:amd64.\n","Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.4_amd64.deb ...\n","Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.4) ...\n","Selecting previously unselected package python-olefile.\n","Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n","Unpacking python-olefile (0.45.1-1) ...\n","Selecting previously unselected package python-pil:amd64.\n","Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.6_amd64.deb ...\n","Unpacking python-pil:amd64 (5.1.0-1ubuntu0.6) ...\n","Setting up python-pkg-resources (39.0.1-2) ...\n","Setting up python-six (1.11.0-2) ...\n","Setting up python-bs4 (4.6.0-1) ...\n","Setting up python-lxml:amd64 (4.2.1-1ubuntu0.4) ...\n","Setting up python-olefile (0.45.1-1) ...\n","Setting up python-pil:amd64 (5.1.0-1ubuntu0.6) ...\n","Setting up python-webencodings (0.5-2) ...\n","Setting up python-chardet (3.0.4-1) ...\n","Setting up python-html5lib (0.999999999-1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"]}]},{"cell_type":"code","metadata":{"id":"qTVaTwiHFmHk","executionInfo":{"status":"ok","timestamp":1632875119549,"user_tz":-540,"elapsed":3299,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}}},"source":["!pip install -qq Cython contextlib2 pillow lxml matplotlib pycocotools"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wGnZeOJ8FmHl","executionInfo":{"status":"ok","timestamp":1632875129451,"user_tz":-540,"elapsed":313,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}},"outputId":"69ad7f73-cdba-41d0-c452-3558dfa94f65"},"source":["# 4. protos 컴파일\n","%cd models/research"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/models/research\n"]}]},{"cell_type":"code","metadata":{"id":"nX-sLsjaFmHm","executionInfo":{"status":"ok","timestamp":1632875167271,"user_tz":-540,"elapsed":321,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}}},"source":["!protoc object_detection/protos/*.proto --python_out=."],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ha6ywhaHP3e1","executionInfo":{"status":"ok","timestamp":1632875190580,"user_tz":-540,"elapsed":302,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}}},"source":["#5. setup.py 실행\n","# setup.py 를 현재 디렉토리로 카피. cp 대상파일 카피경로\n","!cp object_detection/packages/tf2/setup.py ."],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1DRHpB8oP3Ud","executionInfo":{"status":"ok","timestamp":1632875227802,"user_tz":-540,"elapsed":34326,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}},"outputId":"5c61166f-67b6-4417-910d-f6635e92b979"},"source":["# setup.py 를 이용해 추가 패키지 설치\n","!pip install ."],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing /content/models/research\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","Collecting avro-python3\n","  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n","Collecting apache-beam\n","  Downloading apache_beam-2.32.0-cp37-cp37m-manylinux2010_x86_64.whl (9.8 MB)\n","\u001b[K     |████████████████████████████████| 9.8 MB 24.4 MB/s \n","\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.24)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n","Collecting tf-slim\n","  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n","\u001b[K     |████████████████████████████████| 352 kB 56.2 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.2)\n","Collecting lvis\n","  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n","Collecting tf-models-official>=2.5.1\n","  Downloading tf_models_official-2.6.0-py2.py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 22.3 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n","Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n","Collecting opencv-python-headless\n","  Downloading opencv_python_headless-4.5.3.56-cp37-cp37m-manylinux2014_x86_64.whl (37.1 MB)\n","\u001b[K     |████████████████████████████████| 37.1 MB 47 kB/s \n","\u001b[?25hCollecting sacrebleu\n","  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n","\u001b[K     |████████████████████████████████| 90 kB 10.4 MB/s \n","\u001b[?25hCollecting tensorflow-addons\n","  Downloading tensorflow_addons-0.14.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 40.4 MB/s \n","\u001b[?25hCollecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 40.6 MB/s \n","\u001b[?25hCollecting py-cpuinfo>=3.3.0\n","  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n","\u001b[K     |████████████████████████████████| 99 kB 10.0 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.19.5)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 53.1 MB/s \n","\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n","Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.8)\n","Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n","Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 2.5 MB/s \n","\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n","  Downloading tensorflow_model_optimization-0.6.0-py2.py3-none-any.whl (211 kB)\n","\u001b[K     |████████████████████████████████| 211 kB 56.9 MB/s \n","\u001b[?25hRequirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n","Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n","Collecting tensorflow-text>=2.5.0\n","  Downloading tensorflow_text-2.6.0-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\n","\u001b[K     |████████████████████████████████| 4.4 MB 41.6 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n","Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.26.3)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n","Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.53.0)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.0)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2018.9)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.7.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.2)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.62.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.5.30)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (5.0.2)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.4.7)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12)\n","Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.7.4.3)\n","Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (5.0)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12.1)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n","Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n","Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.40.0)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n","Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.4)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (4.8.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.1)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.6)\n","Collecting requests<3.0.0dev,>=2.18.0\n","  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n","\u001b[K     |████████████████████████████████| 62 kB 936 kB/s \n","\u001b[?25hRequirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n","Collecting orjson<4.0\n","  Downloading orjson-3.6.3-cp37-cp37m-manylinux_2_24_x86_64.whl (234 kB)\n","\u001b[K     |████████████████████████████████| 234 kB 61.8 MB/s \n","\u001b[?25hRequirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.12.0)\n","Collecting avro-python3\n","  Downloading avro-python3-1.9.2.1.tar.gz (37 kB)\n","Requirement already satisfied: pyarrow<5.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.0.0)\n","Collecting future<1.0.0,>=0.18.2\n","  Downloading future-0.18.2.tar.gz (829 kB)\n","\u001b[K     |████████████████████████████████| 829 kB 44.2 MB/s \n","\u001b[?25hCollecting fastavro<2,>=0.21.4\n","  Downloading fastavro-1.4.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n","\u001b[K     |████████████████████████████████| 2.3 MB 47.2 MB/s \n","\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n","  Downloading dill-0.3.1.1.tar.gz (151 kB)\n","\u001b[K     |████████████████████████████████| 151 kB 10.5 MB/s \n","\u001b[?25hRequirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n","Collecting hdfs<3.0.0,>=2.1.0\n","  Downloading hdfs-2.6.0-py3-none-any.whl (33 kB)\n","Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.5.0)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.3.2)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n","Collecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n","Collecting portalocker\n","  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2019.12.20)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (0.22.2.post1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.2.2)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n","Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.2.0)\n","Building wheels for collected packages: object-detection, py-cpuinfo, avro-python3, dill, future, seqeval\n","  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1665976 sha256=21a681a9d2e87d7ebbc9cc63b7b086a9a7298c92a1f2fca915ae98ad4ddb61f3\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-ycv97z_b/wheels/fa/a4/d2/e9a5057e414fd46c8e543d2706cd836d64e1fcd9eccceb2329\n","  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22258 sha256=3251bfe3f3b45ef90af5fa82af88911d4d6036a39b6726544359d4429cd9264f\n","  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n","  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for avro-python3: filename=avro_python3-1.9.2.1-py3-none-any.whl size=43512 sha256=1b7fe90e9a88a01f5e472ffa8a3b206fe90e4d02ca55011dc66874168be9aff2\n","  Stored in directory: /root/.cache/pip/wheels/bc/49/5f/fdb5b9d85055c478213e0158ac122b596816149a02d82e0ab1\n","  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78546 sha256=c73ade04d115e70713203972d3c5d58053cc6688dcaaed90f535e0e7398ae321\n","  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=89e403a13956ea610ccf4e8a0c25d0f7de0dc750c90ec09295d87e2e9275451b\n","  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=6b365e50c55c402947c56a31e2eb0b06820449272d04b28b4df2cc8d8e244bb7\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built object-detection py-cpuinfo avro-python3 dill future seqeval\n","Installing collected packages: requests, portalocker, future, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, py-cpuinfo, orjson, opencv-python-headless, hdfs, fastavro, avro-python3, tf-models-official, lvis, apache-beam, object-detection\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: future\n","    Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","  Attempting uninstall: dill\n","    Found existing installation: dill 0.3.4\n","    Uninstalling dill-0.3.4:\n","      Successfully uninstalled dill-0.3.4\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed apache-beam-2.32.0 avro-python3-1.9.2.1 colorama-0.4.4 dill-0.3.1.1 fastavro-1.4.5 future-0.18.2 hdfs-2.6.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.3.56 orjson-3.6.3 portalocker-2.3.2 py-cpuinfo-8.0.0 pyyaml-5.4.1 requests-2.26.0 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.14.0 tensorflow-model-optimization-0.6.0 tensorflow-text-2.6.0 tf-models-official-2.6.0 tf-slim-1.1.0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oJbKD8qgP3F9","executionInfo":{"status":"ok","timestamp":1632875252210,"user_tz":-540,"elapsed":336,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}},"outputId":"3e6e51e0-508d-44eb-bf94-196e73b4fa52"},"source":["!pwd"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/models/research\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uW9oNva-P3DL","executionInfo":{"status":"ok","timestamp":1632875254253,"user_tz":-540,"elapsed":308,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}},"outputId":"fc50f901-002b-4a74-ac08-678356df1675"},"source":["# 작업 디렉토리 /content 로 이동  ..: 상대경로-상위디렉토리  /: 디렉토리구분자\n","%cd  ../..\n","cd ../.."],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FJiZYYuLRGGr","executionInfo":{"status":"ok","timestamp":1632875373346,"user_tz":-540,"elapsed":37284,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}},"outputId":"9a10903e-6ea4-47ef-8c0e-2d7b0e51234b"},"source":["# 설치 잘되었는지 확인\n","!python models/research/object_detection/builders/model_builder_tf2_test.py"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["2021-09-29 00:28:59.823124: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","2021-09-29 00:28:59.823187: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (6aca4916ae49): /proc/driver/nvidia/version does not exist\n","Running tests under Python 3.7.12: /usr/bin/python3\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","W0929 00:29:00.170686 139704533366656 model_builder.py:1091] Building experimental DeepMAC meta-arch. Some features may be omitted.\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.74s\n","I0929 00:29:00.567780 139704533366656 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.74s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.54s\n","I0929 00:29:01.112260 139704533366656 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.54s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.3s\n","I0929 00:29:01.413588 139704533366656 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.3s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.28s\n","I0929 00:29:01.691807 139704533366656 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.28s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.16s\n","I0929 00:29:03.848799 139704533366656 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.16s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","I0929 00:29:03.849838 139704533366656 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n","I0929 00:29:03.874970 139704533366656 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n","I0929 00:29:03.891536 139704533366656 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n","I0929 00:29:03.908797 139704533366656 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.11s\n","I0929 00:29:04.019453 139704533366656 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.11s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.11s\n","I0929 00:29:04.129304 139704533366656 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.11s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.11s\n","I0929 00:29:04.240880 139704533366656 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.11s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.11s\n","I0929 00:29:04.354163 139704533366656 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.11s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.11s\n","I0929 00:29:04.462000 139704533366656 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.11s\n","[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n","I0929 00:29:04.493451 139704533366656 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","I0929 00:29:04.831003 139704533366656 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I0929 00:29:04.831215 139704533366656 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n","I0929 00:29:04.831300 139704533366656 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 3\n","I0929 00:29:04.833689 139704533366656 efficientnet_model.py:147] round_filter input=32 output=32\n","I0929 00:29:04.850539 139704533366656 efficientnet_model.py:147] round_filter input=32 output=32\n","I0929 00:29:04.850704 139704533366656 efficientnet_model.py:147] round_filter input=16 output=16\n","I0929 00:29:04.908745 139704533366656 efficientnet_model.py:147] round_filter input=16 output=16\n","I0929 00:29:04.908935 139704533366656 efficientnet_model.py:147] round_filter input=24 output=24\n","I0929 00:29:05.066311 139704533366656 efficientnet_model.py:147] round_filter input=24 output=24\n","I0929 00:29:05.066568 139704533366656 efficientnet_model.py:147] round_filter input=40 output=40\n","I0929 00:29:05.236458 139704533366656 efficientnet_model.py:147] round_filter input=40 output=40\n","I0929 00:29:05.236659 139704533366656 efficientnet_model.py:147] round_filter input=80 output=80\n","I0929 00:29:05.497138 139704533366656 efficientnet_model.py:147] round_filter input=80 output=80\n","I0929 00:29:05.497362 139704533366656 efficientnet_model.py:147] round_filter input=112 output=112\n","I0929 00:29:05.772654 139704533366656 efficientnet_model.py:147] round_filter input=112 output=112\n","I0929 00:29:05.772851 139704533366656 efficientnet_model.py:147] round_filter input=192 output=192\n","I0929 00:29:06.171857 139704533366656 efficientnet_model.py:147] round_filter input=192 output=192\n","I0929 00:29:06.172057 139704533366656 efficientnet_model.py:147] round_filter input=320 output=320\n","I0929 00:29:06.267079 139704533366656 efficientnet_model.py:147] round_filter input=1280 output=1280\n","I0929 00:29:06.317165 139704533366656 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0929 00:29:06.375752 139704533366656 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b1\n","I0929 00:29:06.375938 139704533366656 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 88\n","I0929 00:29:06.376001 139704533366656 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 4\n","I0929 00:29:06.377850 139704533366656 efficientnet_model.py:147] round_filter input=32 output=32\n","I0929 00:29:06.393733 139704533366656 efficientnet_model.py:147] round_filter input=32 output=32\n","I0929 00:29:06.393895 139704533366656 efficientnet_model.py:147] round_filter input=16 output=16\n","I0929 00:29:06.520442 139704533366656 efficientnet_model.py:147] round_filter input=16 output=16\n","I0929 00:29:06.520627 139704533366656 efficientnet_model.py:147] round_filter input=24 output=24\n","I0929 00:29:06.762539 139704533366656 efficientnet_model.py:147] round_filter input=24 output=24\n","I0929 00:29:06.762728 139704533366656 efficientnet_model.py:147] round_filter input=40 output=40\n","I0929 00:29:07.001558 139704533366656 efficientnet_model.py:147] round_filter input=40 output=40\n","I0929 00:29:07.001744 139704533366656 efficientnet_model.py:147] round_filter input=80 output=80\n","I0929 00:29:07.327310 139704533366656 efficientnet_model.py:147] round_filter input=80 output=80\n","I0929 00:29:07.327500 139704533366656 efficientnet_model.py:147] round_filter input=112 output=112\n","I0929 00:29:07.673926 139704533366656 efficientnet_model.py:147] round_filter input=112 output=112\n","I0929 00:29:07.674112 139704533366656 efficientnet_model.py:147] round_filter input=192 output=192\n","I0929 00:29:08.155256 139704533366656 efficientnet_model.py:147] round_filter input=192 output=192\n","I0929 00:29:08.155467 139704533366656 efficientnet_model.py:147] round_filter input=320 output=320\n","I0929 00:29:08.384615 139704533366656 efficientnet_model.py:147] round_filter input=1280 output=1280\n","I0929 00:29:08.439724 139704533366656 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0929 00:29:08.646278 139704533366656 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b2\n","I0929 00:29:08.646459 139704533366656 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 112\n","I0929 00:29:08.646523 139704533366656 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 5\n","I0929 00:29:08.648589 139704533366656 efficientnet_model.py:147] round_filter input=32 output=32\n","I0929 00:29:08.664435 139704533366656 efficientnet_model.py:147] round_filter input=32 output=32\n","I0929 00:29:08.664577 139704533366656 efficientnet_model.py:147] round_filter input=16 output=16\n","I0929 00:29:08.785852 139704533366656 efficientnet_model.py:147] round_filter input=16 output=16\n","I0929 00:29:08.786054 139704533366656 efficientnet_model.py:147] round_filter input=24 output=24\n","I0929 00:29:09.023590 139704533366656 efficientnet_model.py:147] round_filter input=24 output=24\n","I0929 00:29:09.023783 139704533366656 efficientnet_model.py:147] round_filter input=40 output=48\n","I0929 00:29:09.280106 139704533366656 efficientnet_model.py:147] round_filter input=40 output=48\n","I0929 00:29:09.280327 139704533366656 efficientnet_model.py:147] round_filter input=80 output=88\n","I0929 00:29:09.633411 139704533366656 efficientnet_model.py:147] round_filter input=80 output=88\n","I0929 00:29:09.633618 139704533366656 efficientnet_model.py:147] round_filter input=112 output=120\n","I0929 00:29:10.001247 139704533366656 efficientnet_model.py:147] round_filter input=112 output=120\n","I0929 00:29:10.001437 139704533366656 efficientnet_model.py:147] round_filter input=192 output=208\n","I0929 00:29:10.472147 139704533366656 efficientnet_model.py:147] round_filter input=192 output=208\n","I0929 00:29:10.472376 139704533366656 efficientnet_model.py:147] round_filter input=320 output=352\n","I0929 00:29:10.706480 139704533366656 efficientnet_model.py:147] round_filter input=1280 output=1408\n","I0929 00:29:10.766699 139704533366656 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0929 00:29:10.838955 139704533366656 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b3\n","I0929 00:29:10.839144 139704533366656 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 160\n","I0929 00:29:10.839251 139704533366656 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 6\n","I0929 00:29:10.841146 139704533366656 efficientnet_model.py:147] round_filter input=32 output=40\n","I0929 00:29:10.859142 139704533366656 efficientnet_model.py:147] round_filter input=32 output=40\n","I0929 00:29:10.859351 139704533366656 efficientnet_model.py:147] round_filter input=16 output=24\n","I0929 00:29:10.985214 139704533366656 efficientnet_model.py:147] round_filter input=16 output=24\n","I0929 00:29:10.985405 139704533366656 efficientnet_model.py:147] round_filter input=24 output=32\n","I0929 00:29:11.217813 139704533366656 efficientnet_model.py:147] round_filter input=24 output=32\n","I0929 00:29:11.218003 139704533366656 efficientnet_model.py:147] round_filter input=40 output=48\n","I0929 00:29:11.453435 139704533366656 efficientnet_model.py:147] round_filter input=40 output=48\n","I0929 00:29:11.453624 139704533366656 efficientnet_model.py:147] round_filter input=80 output=96\n","I0929 00:29:11.874249 139704533366656 efficientnet_model.py:147] round_filter input=80 output=96\n","I0929 00:29:11.874444 139704533366656 efficientnet_model.py:147] round_filter input=112 output=136\n","I0929 00:29:12.299907 139704533366656 efficientnet_model.py:147] round_filter input=112 output=136\n","I0929 00:29:12.300093 139704533366656 efficientnet_model.py:147] round_filter input=192 output=232\n","I0929 00:29:12.895964 139704533366656 efficientnet_model.py:147] round_filter input=192 output=232\n","I0929 00:29:12.896180 139704533366656 efficientnet_model.py:147] round_filter input=320 output=384\n","I0929 00:29:13.139204 139704533366656 efficientnet_model.py:147] round_filter input=1280 output=1536\n","I0929 00:29:13.204714 139704533366656 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0929 00:29:13.479257 139704533366656 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b4\n","I0929 00:29:13.479443 139704533366656 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 224\n","I0929 00:29:13.479505 139704533366656 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n","I0929 00:29:13.481693 139704533366656 efficientnet_model.py:147] round_filter input=32 output=48\n","I0929 00:29:13.504258 139704533366656 efficientnet_model.py:147] round_filter input=32 output=48\n","I0929 00:29:13.504488 139704533366656 efficientnet_model.py:147] round_filter input=16 output=24\n","I0929 00:29:13.634423 139704533366656 efficientnet_model.py:147] round_filter input=16 output=24\n","I0929 00:29:13.634603 139704533366656 efficientnet_model.py:147] round_filter input=24 output=32\n","I0929 00:29:13.952748 139704533366656 efficientnet_model.py:147] round_filter input=24 output=32\n","I0929 00:29:13.952937 139704533366656 efficientnet_model.py:147] round_filter input=40 output=56\n","I0929 00:29:14.282799 139704533366656 efficientnet_model.py:147] round_filter input=40 output=56\n","I0929 00:29:14.283002 139704533366656 efficientnet_model.py:147] round_filter input=80 output=112\n","I0929 00:29:14.786762 139704533366656 efficientnet_model.py:147] round_filter input=80 output=112\n","I0929 00:29:14.786962 139704533366656 efficientnet_model.py:147] round_filter input=112 output=160\n","I0929 00:29:15.321506 139704533366656 efficientnet_model.py:147] round_filter input=112 output=160\n","I0929 00:29:15.321715 139704533366656 efficientnet_model.py:147] round_filter input=192 output=272\n","I0929 00:29:16.178813 139704533366656 efficientnet_model.py:147] round_filter input=192 output=272\n","I0929 00:29:16.179016 139704533366656 efficientnet_model.py:147] round_filter input=320 output=448\n","I0929 00:29:16.447188 139704533366656 efficientnet_model.py:147] round_filter input=1280 output=1792\n","I0929 00:29:16.515979 139704533366656 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0929 00:29:16.603818 139704533366656 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b5\n","I0929 00:29:16.603994 139704533366656 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 288\n","I0929 00:29:16.604057 139704533366656 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n","I0929 00:29:16.605848 139704533366656 efficientnet_model.py:147] round_filter input=32 output=48\n","I0929 00:29:16.621643 139704533366656 efficientnet_model.py:147] round_filter input=32 output=48\n","I0929 00:29:16.621790 139704533366656 efficientnet_model.py:147] round_filter input=16 output=24\n","I0929 00:29:16.817933 139704533366656 efficientnet_model.py:147] round_filter input=16 output=24\n","I0929 00:29:16.818141 139704533366656 efficientnet_model.py:147] round_filter input=24 output=40\n","I0929 00:29:17.213690 139704533366656 efficientnet_model.py:147] round_filter input=24 output=40\n","I0929 00:29:17.213879 139704533366656 efficientnet_model.py:147] round_filter input=40 output=64\n","I0929 00:29:17.620501 139704533366656 efficientnet_model.py:147] round_filter input=40 output=64\n","I0929 00:29:17.620700 139704533366656 efficientnet_model.py:147] round_filter input=80 output=128\n","I0929 00:29:18.230086 139704533366656 efficientnet_model.py:147] round_filter input=80 output=128\n","I0929 00:29:18.230317 139704533366656 efficientnet_model.py:147] round_filter input=112 output=176\n","I0929 00:29:19.136194 139704533366656 efficientnet_model.py:147] round_filter input=112 output=176\n","I0929 00:29:19.136390 139704533366656 efficientnet_model.py:147] round_filter input=192 output=304\n","I0929 00:29:20.149481 139704533366656 efficientnet_model.py:147] round_filter input=192 output=304\n","I0929 00:29:20.149684 139704533366656 efficientnet_model.py:147] round_filter input=320 output=512\n","I0929 00:29:20.613966 139704533366656 efficientnet_model.py:147] round_filter input=1280 output=2048\n","I0929 00:29:20.692932 139704533366656 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0929 00:29:20.797082 139704533366656 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b6\n","I0929 00:29:20.797286 139704533366656 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n","I0929 00:29:20.797352 139704533366656 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n","I0929 00:29:20.799142 139704533366656 efficientnet_model.py:147] round_filter input=32 output=56\n","I0929 00:29:20.819190 139704533366656 efficientnet_model.py:147] round_filter input=32 output=56\n","I0929 00:29:20.819412 139704533366656 efficientnet_model.py:147] round_filter input=16 output=32\n","I0929 00:29:21.013210 139704533366656 efficientnet_model.py:147] round_filter input=16 output=32\n","I0929 00:29:21.013394 139704533366656 efficientnet_model.py:147] round_filter input=24 output=40\n","I0929 00:29:21.494855 139704533366656 efficientnet_model.py:147] round_filter input=24 output=40\n","I0929 00:29:21.495049 139704533366656 efficientnet_model.py:147] round_filter input=40 output=72\n","I0929 00:29:21.987651 139704533366656 efficientnet_model.py:147] round_filter input=40 output=72\n","I0929 00:29:21.987863 139704533366656 efficientnet_model.py:147] round_filter input=80 output=144\n","I0929 00:29:22.684194 139704533366656 efficientnet_model.py:147] round_filter input=80 output=144\n","I0929 00:29:22.684396 139704533366656 efficientnet_model.py:147] round_filter input=112 output=200\n","I0929 00:29:23.460345 139704533366656 efficientnet_model.py:147] round_filter input=112 output=200\n","I0929 00:29:23.460545 139704533366656 efficientnet_model.py:147] round_filter input=192 output=344\n","I0929 00:29:25.066736 139704533366656 efficientnet_model.py:147] round_filter input=192 output=344\n","I0929 00:29:25.066952 139704533366656 efficientnet_model.py:147] round_filter input=320 output=576\n","I0929 00:29:25.595687 139704533366656 efficientnet_model.py:147] round_filter input=1280 output=2304\n","I0929 00:29:25.683784 139704533366656 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0929 00:29:25.800962 139704533366656 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b7\n","I0929 00:29:25.801142 139704533366656 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n","I0929 00:29:25.801219 139704533366656 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n","I0929 00:29:25.802981 139704533366656 efficientnet_model.py:147] round_filter input=32 output=64\n","I0929 00:29:25.818736 139704533366656 efficientnet_model.py:147] round_filter input=32 output=64\n","I0929 00:29:25.818905 139704533366656 efficientnet_model.py:147] round_filter input=16 output=32\n","I0929 00:29:26.077711 139704533366656 efficientnet_model.py:147] round_filter input=16 output=32\n","I0929 00:29:26.077898 139704533366656 efficientnet_model.py:147] round_filter input=24 output=48\n","I0929 00:29:26.632347 139704533366656 efficientnet_model.py:147] round_filter input=24 output=48\n","I0929 00:29:26.632531 139704533366656 efficientnet_model.py:147] round_filter input=40 output=80\n","I0929 00:29:27.215672 139704533366656 efficientnet_model.py:147] round_filter input=40 output=80\n","I0929 00:29:27.215885 139704533366656 efficientnet_model.py:147] round_filter input=80 output=160\n","I0929 00:29:28.106580 139704533366656 efficientnet_model.py:147] round_filter input=80 output=160\n","I0929 00:29:28.106790 139704533366656 efficientnet_model.py:147] round_filter input=112 output=224\n","I0929 00:29:29.094637 139704533366656 efficientnet_model.py:147] round_filter input=112 output=224\n","I0929 00:29:29.094829 139704533366656 efficientnet_model.py:147] round_filter input=192 output=384\n","I0929 00:29:30.842256 139704533366656 efficientnet_model.py:147] round_filter input=192 output=384\n","I0929 00:29:30.842453 139704533366656 efficientnet_model.py:147] round_filter input=320 output=640\n","I0929 00:29:31.935073 139704533366656 efficientnet_model.py:147] round_filter input=1280 output=2560\n","I0929 00:29:32.032833 139704533366656 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 27.68s\n","I0929 00:29:32.174006 139704533366656 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 27.68s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","I0929 00:29:32.180963 139704533366656 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","I0929 00:29:32.182902 139704533366656 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","I0929 00:29:32.183413 139704533366656 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","I0929 00:29:32.185104 139704533366656 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","[ RUN      ] ModelBuilderTF2Test.test_session\n","[  SKIPPED ] ModelBuilderTF2Test.test_session\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","I0929 00:29:32.186640 139704533366656 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","I0929 00:29:32.187077 139704533366656 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","I0929 00:29:32.188189 139704533366656 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","----------------------------------------------------------------------\n","Ran 24 tests in 32.362s\n","\n","OK (skipped=1)\n"]}]},{"cell_type":"markdown","metadata":{"id":"lq7nfAo7FmHn"},"source":["# 경로 설정\n","- 프로젝트 진행도중 필요한 파일들을 저장하는 디렉토리나 파일의 경로들을 문자열로 미리 저장해 놓는다."]},{"cell_type":"code","metadata":{"id":"qLnMcfIrYGfS","executionInfo":{"status":"ok","timestamp":1632875985345,"user_tz":-540,"elapsed":329,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}}},"source":["import os\n","\n","# ROOT 경로 (workspace)\n","BASE_PATH = \"/content/drive/MyDrive/object_detection_src/sign_language_letters/workspace\"\n","# utility 기능을 구현한 python script 파일들이 있는 디렉토리.\n","SCRIPTS_PATH = \"/content/drive/MyDrive/object_detection_src/sign_language_letters/scripts\"\n","# Tensorflow Object Detection API2 경로\n","TF_OD_API_PATH = \"/content/models\"\n","# Image/Annotation 파일들의 경로\n","IMAGE_PATH = '/content/images'\n","\n","# Label Map 파일을 저장할 디렉토리 경로, 파일 경로 - Label map 설정파일: 분류할 class 들을 정의한 파일.\n","LABEL_MAP_PATH = os.path.join(BASE_PATH, 'labelmap')\n","LABEL_MAP_FILE_PATH = os.path.join(LABEL_MAP_PATH, 'label_map.pbtxt')\n","\n","# TF Record를 저장할 경로\n","# Dataset 관련 파일들은 Google Drive 보다는 local 에 저장\n","TF_RECORD_PATH = '/content/tfrecord'\n","if not os.path.isdir(TF_RECORD_PATH):\n","    os.mkdir(TF_RECORD_PATH)\n","\n","# CUSTOM DATASET을 학습한 모델(모델, wegith파일)을 저장할 경로\n","MODEL_PATH = os.path.join(BASE_PATH, 'model')\n","CHECK_POINT_PATH = os.path.join(MODEL_PATH, 'checkpoint') # weights(파라미터) 저장할 디렉토리.\n","EXPORT_MODEL_PATH = os.path.join(MODEL_PATH, 'export_model') # 학습된 모델(모델+wegiht)을 추출하여 저장할 디렉토리.\n","# pipeline.config 파일: 모델구조, 학습에 필요한 정보, 평가시 필요한 정보를 설정하는 파일. 이 파일의 경로지정.\n","PIPELINE_CONFIG_PATH = os.path.join(MODEL_PATH, \"pipeline.config\")\n","\n","# 전이학습에 사용할 다운받은 모델을 저장할 디렉토리.\n","PRE_TRAINED_MODEL_PATH = os.path.join(BASE_PATH, 'pre_trained_model')"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XLD2Wh-JFmHq"},"source":["# Custom data 학습 시키기\n","\n","## 다음 세가지 작업이 필요\n","<span style='font-weight:bold;font-size:1.3em'>1. Label Map 파일 생성</span>\n","- 분류 하고자 하는 object의 class와 그 class id 를 pbtxt text 파일로 작성\n","- `models\\research\\object_detection\\data`\n","\n","```\n","item {\n","  id: 1\n","  name: 'aeroplane'\n","}\n","\n","item {\n","  id: 2\n","  name: 'bicycle'\n","}\n","...\n","```\n","\n","<span style='font-weight:bold;font-size:1.3em'>2. pipeline.config</span>\n","- Model을 학습, 검증하기 위해 필요한 설정을 하는 파일\n","- `models\\research\\object_detection\\samples\\configs`\n","\n","<span style='font-weight:bold;font-size:1.3em'>3. 학습/검증/테스트에 사용할 데이터셋을 TFRecord 로 구성</span>\n","- 주요 데이터셋을 TFRecord로 생성하는 코드\n","- `models\\research\\object_detection\\dataset_tools`"]},{"cell_type":"markdown","metadata":{"id":"SB479b3vFmHr"},"source":["# 설정파일 설정 및 데이터셋 준비"]},{"cell_type":"markdown","metadata":{"id":"7eiA31MaFmHs"},"source":["# Label Map 생성\n","- class:  A ~ Z"]},{"cell_type":"code","metadata":{"id":"X4H4j0ZMFmHu","executionInfo":{"status":"ok","timestamp":1632876386052,"user_tz":-540,"elapsed":316,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}}},"source":["names = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n","ids = range(1, 27)\n","# len(names), names"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"HTBD3R2GFmHv","executionInfo":{"status":"ok","timestamp":1632876388608,"user_tz":-540,"elapsed":815,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}}},"source":["# File IO를 이용해 Label Map 파일을 출력\n","with open(LABEL_MAP_FILE_PATH, 'wt') as fw:\n","    for id, name in zip(ids, names):\n","        fw.write('item {\\n')\n","        fw.write(f'\\tid:{id}\\n')\n","        fw.write(f\"\\tname:'{name}'\\n\")\n","        fw.write(\"}\\n\")"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"tg8O7a5c5lE1"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j3EdviO8FmHw"},"source":["# TFRecord 생성\n","- `scripts/generate_tfrecord.py` 을 사용해서 생성- \n","- command line argument\n","    - `-x, --xml_dir`: annotation xml 파일들이 있는 디렉토리 경로\n","    - `-l, --labels_path`: label map 파일 경로(파일명 포함)\n","    - `-o, --output_path`: 생성된 tfrecord파일 경로(파일명 포함)\n","    - `-i, --image_dir`: 이미지 파일들이 있는 디렉토리 경로 (annotation 파일과 동일한 경로에 있으면 생략가능)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"id":"MnvV8ZsHFmHw","executionInfo":{"status":"ok","timestamp":1632876660804,"user_tz":-540,"elapsed":478,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}},"outputId":"717442ec-c0af-49cf-9fbe-8123743d9994"},"source":["# TRAIN SET \n","f\"!python {SCRIPTS_PATH}/generate_tfrecord.py  -x {IMAGE_PATH}/train  -l {LABEL_MAP_FILE_PATH}  -o {TF_RECORD_PATH}/train.tfr\""],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'!python /content/drive/MyDrive/object_detection_src/sign_language_letters/scripts/generate_tfrecord.py  -x /content/images/train  -l /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/labelmap/label_map.pbtxt  -o /content/tfrecord/train.tfr'"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X_KKWivCFmHx","executionInfo":{"status":"ok","timestamp":1632876667078,"user_tz":-540,"elapsed":4878,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}},"outputId":"f22fb608-3b06-4df6-f824-bb473c7643fd"},"source":["!python /content/drive/MyDrive/object_detection_src/sign_language_letters/scripts/generate_tfrecord.py  -x /content/images/train  -l /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/labelmap/label_map.pbtxt  -o /content/tfrecord/train.tfr"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["2021-09-29 00:51:04.801544: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","Successfully created the TFRecord file: /content/tfrecord/train.tfr\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"id":"iOvkka4cFmHx","executionInfo":{"status":"ok","timestamp":1632876667082,"user_tz":-540,"elapsed":30,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}},"outputId":"4519872d-ccec-4435-e2f5-769a3fd0ae3c"},"source":["# VALIDATION SET\n","f\"!python {SCRIPTS_PATH}/generate_tfrecord.py  -x {IMAGE_PATH}/valid  -l {LABEL_MAP_FILE_PATH}  -o {TF_RECORD_PATH}/valid.tfr\""],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'!python /content/drive/MyDrive/object_detection_src/sign_language_letters/scripts/generate_tfrecord.py  -x /content/images/valid  -l /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/labelmap/label_map.pbtxt  -o /content/tfrecord/valid.tfr'"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ywLMwDS0FmHx","executionInfo":{"status":"ok","timestamp":1632876672089,"user_tz":-540,"elapsed":3525,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}},"outputId":"009b5f97-e9cb-48b6-ff57-a228b73179aa"},"source":["!python /content/drive/MyDrive/object_detection_src/sign_language_letters/scripts/generate_tfrecord.py  -x /content/images/valid  -l /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/labelmap/label_map.pbtxt  -o /content/tfrecord/valid.tfr"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["2021-09-29 00:51:10.942344: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","Successfully created the TFRecord file: /content/tfrecord/valid.tfr\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"id":"ddCv7AYMJo0B","executionInfo":{"status":"ok","timestamp":1632876672094,"user_tz":-540,"elapsed":15,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}},"outputId":"12129a13-019a-4933-9c52-e85ce6fced0b"},"source":["# Test set\n","f\"!python {SCRIPTS_PATH}/generate_tfrecord.py  -x {IMAGE_PATH}/test  -l {LABEL_MAP_FILE_PATH}  -o {TF_RECORD_PATH}/test.tfr\""],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'!python /content/drive/MyDrive/object_detection_src/sign_language_letters/scripts/generate_tfrecord.py  -x /content/images/test  -l /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/labelmap/label_map.pbtxt  -o /content/tfrecord/test.tfr'"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mXvyeOf-Josh","executionInfo":{"status":"ok","timestamp":1632876675069,"user_tz":-540,"elapsed":2987,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}},"outputId":"36a53058-c551-47c4-c8d0-7dd16442a955"},"source":["!python /content/drive/MyDrive/object_detection_src/sign_language_letters/scripts/generate_tfrecord.py  -x /content/images/test  -l /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/labelmap/label_map.pbtxt  -o /content/tfrecord/test.tfr"],"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["2021-09-29 00:51:14.102892: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","Successfully created the TFRecord file: /content/tfrecord/test.tfr\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"MSAlM-cEKm1A","executionInfo":{"status":"ok","timestamp":1632811871628,"user_tz":-540,"elapsed":332,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}},"outputId":"8c4e0044-7ce1-4c0b-87f8-756f8bfa5a51"},"source":["# 생성된 tfrecord 파일을 google driver 카피(백업)\n","\n","f\"!cp {TF_RECORD_PATH}/*.tfr  {os.path.join(BASE_PATH, 'tfrecord')}\""],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'!cp /content/tfrecord/*.tfr  /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/tfrecord'"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"z2Mu_jOSKmyO"},"source":["!cp /content/tfrecord/*.tfr  /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/tfrecord"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n26aEg3vFmHy"},"source":["# Pretrained Model Download\n","- Tensorflow object detection API는 MS COCO 2017 dataset으로 미리 학습시킨 다양한 Object Detection 모델을 제공한다.\n","- tf2 detection Model Zoo: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\n","- SSD MobileNet V2 FPNLite 320x320 다운로드\n","    - 성능은 떨어지지만 학습속도가 빠르다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"85O-5lRNFmHz","executionInfo":{"status":"ok","timestamp":1632876884395,"user_tz":-540,"elapsed":780,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}},"outputId":"bd8c757a-44ca-4ddd-a7eb-45d9e9c777ae"},"source":["# wget url  : url의 파일을 다운로드 하는 리눅스 명령어\n","!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["--2021-09-29 00:54:43--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n","Resolving download.tensorflow.org (download.tensorflow.org)... 142.250.81.208, 2607:f8b0:4004:82f::2010\n","Connecting to download.tensorflow.org (download.tensorflow.org)|142.250.81.208|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 20515344 (20M) [application/x-tar]\n","Saving to: ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’\n","\n","ssd_mobilenet_v2_fp 100%[===================>]  19.56M  89.7MB/s    in 0.2s    \n","\n","2021-09-29 00:54:44 (89.7 MB/s) - ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’ saved [20515344/20515344]\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"uCrIMBrDFmHz","executionInfo":{"status":"ok","timestamp":1632876898423,"user_tz":-540,"elapsed":355,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}},"outputId":"b0604070-7fb0-425d-e62f-643a888b50d3"},"source":["# 다운받은 모델을 google drive로 옮기고 압축을 푼다.\n","# 옮기기: mv  원본경로   목적경로\n","f\"!mv  ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz  {PRE_TRAINED_MODEL_PATH}\""],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'!mv  ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz  /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/pre_trained_model'"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"qTcagnUUFmH0","executionInfo":{"status":"ok","timestamp":1632876900302,"user_tz":-540,"elapsed":579,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}}},"source":["!mv  ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz  /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/pre_trained_model"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"id":"aTLWKfF7FmH0","executionInfo":{"status":"ok","timestamp":1632876901479,"user_tz":-540,"elapsed":23,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}},"outputId":"894261b3-c153-477d-8b25-4b9a58941609"},"source":["# 압축 풀기 # tar.gz : tar  -zxvf  압축파일경로   -C  풀경로\n","f\"!tar  -zxvf  {PRE_TRAINED_MODEL_PATH}/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz  -C  {PRE_TRAINED_MODEL_PATH}\""],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'!tar  -zxvf  /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/pre_trained_model/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz  -C  /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/pre_trained_model'"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PdeGlT5fVvMx","executionInfo":{"status":"ok","timestamp":1632876904484,"user_tz":-540,"elapsed":1336,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}},"outputId":"2d734c4b-7f8c-48f7-8c14-df8812a076b3"},"source":["!tar  -zxvf  /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/pre_trained_model/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz  -C  /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/pre_trained_model"],"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"]}]},{"cell_type":"markdown","metadata":{"id":"a2nJ7z1ZFmH0"},"source":["# pipeline.config 설정 변경"]},{"cell_type":"markdown","metadata":{"id":"M3kNbo6_FmH1"},"source":["## pipeline.config  파일 개요\n","- Model을 학습, 검증하기 위해 필요한 설정을 하는 파일\n","- 구조\n","    - https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/configuring_jobs.md\n","    - **model**\n","        - 사용하는 모델에 대한 설정\n","        - class 개수\n","        - 입력이미지 size\n","        - anchor 설정\n","    - **train_config**\n","        - Train(학습)관련 설정\n","        - batch_size\n","            - 사용하는 GPU의 메모리 크기에 맞게 조절한다.\n","        - image augmentation관련 설정 등\n","        - optimizer관련 설정\n","        - 학습에 사용할 weight 파일의 경로\n","    - **train_input_reader**\n","        - labelmap 파일 경로\n","        - train tfrecord 파일 경로\n","    - **eval_config**\n","        - evaluation(평가)을 위해 사용하는 metric 설정\n","    - **eval_input_reader**\n","        - labelmap 파일 경로\n","        - evaluation tfreord 파일 경로\n","        "]},{"cell_type":"markdown","metadata":{"id":"B7RbkQiEFmH2"},"source":["## Pretrain model의 pipeline.config 파일 카피\n","- pretrained 모델의 압축을 풀면 pipeline.config 파일이 있다.\n","- workspace\\model 로 copy 한다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"EywlTLAMevFc","executionInfo":{"status":"ok","timestamp":1632877915755,"user_tz":-540,"elapsed":294,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}},"outputId":"bcd36130-fb43-420b-a6bc-ec60b6072f39"},"source":["PRE_TRAINED_MODEL_PATH = os.path.join(PRE_TRAINED_MODEL_PATH, \"ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\")\n","PRE_TRAINED_MODEL_PATH"],"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/pre_trained_model/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"id":"votNHuQ2FmH2","executionInfo":{"status":"ok","timestamp":1632877976608,"user_tz":-540,"elapsed":356,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}},"outputId":"6dc7837b-40c0-4aaa-faeb-7ff3a9727a17"},"source":["f\"!cp {os.path.join(PRE_TRAINED_MODEL_PATH, 'pipeline.config')}  {PIPELINE_CONFIG_PATH}\""],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'!cp /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/pre_trained_model/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config  /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/model/pipeline.config'"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"Lcmr8W92FmH3","executionInfo":{"status":"ok","timestamp":1632877979314,"user_tz":-540,"elapsed":784,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}}},"source":["!cp /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/pre_trained_model/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config  /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/model/pipeline.config"],"execution_count":32,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8zlPVf-kFmH3"},"source":["## pipeline.config 설정 변경\n","- pipeline.config 내용 변경은 파일을 **직접 변경**할 수도 있고 **코드상에서 변경**할 수도 있다.\n","\n","### 필수 변경사항\n","-  class개수 변경\n","-  train 배치 사이즈 변경 - gpu 메모리 사양에 맞게 변경한다.\n","-  pretrained model 경로 설정\n","-  pretrained model이 어떤 종류의 모델인지 설정\n","-  train 관련 변경\n","    -  labelmap 파일 경로 설정\n","    -  train 용 tfrecord 파일 경로 지정\n","-  evaluation 관련 변경\n","    -  labelmap 파일 경로 설정\n","    -  evaluation 용 tfrecord 파일 경로 지정"]},{"cell_type":"code","metadata":{"id":"rBmhxexzFmIC","executionInfo":{"status":"ok","timestamp":1632878968844,"user_tz":-540,"elapsed":2028,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}}},"source":["# Tensorflow Object Detection API 에서 제공하는 Library를 이용해 pipeline.config 변환 작업\n","import tensorflow as tf\n","from object_detection.utils import config_util\n","from object_detection.protos import pipeline_pb2\n","from google.protobuf import text_format"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"0CFp02c0FmIH"},"source":["# pipeline.config 파일을 읽어서 확인\n","config = config_util.get_configs_from_pipeline_file(PIPELINE_CONFIG_PATH) #경로의 pipeline.config파일의 설정을 딕셔너리로 읽어온다.\n","print(type(config))\n","config"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HbsOgh7-FmIH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632879478823,"user_tz":-540,"elapsed":298,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}},"outputId":"277e722c-500a-4bf9-ad5c-b61911025918"},"source":["# 수정작업\n","# 빈 pipeline.config 템플릿을 생성\n","pipeline_config = pipeline_pb2.TrainEvalPipelineConfig() # pipeline.config의 속성들을 수정하는 기능을 제공.\n","print(type(pipeline_config))\n","print(pipeline_config)"],"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'object_detection.protos.pipeline_pb2.TrainEvalPipelineConfig'>\n","\n"]}]},{"cell_type":"code","metadata":{"id":"8SZHqX27FmIM","executionInfo":{"status":"ok","timestamp":1632879805952,"user_tz":-540,"elapsed":303,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}}},"source":["#pipeline.config의 내용을 text로 읽어서 TrainEvalPipelineConfig(템플릿-틀)에 넣는다.\n","with tf.io.gfile.GFile(PIPELINE_CONFIG_PATH, 'r') as fr: # open()의 Tensorflow 버전\n","    proto_str = fr.read() #text(string)로 읽기. \n","    text_format.Merge(proto_str, pipeline_config) # 읽은 설정 text를 속성단위로 나눠서 TrainEvalPipelineConfig 에 넣어준다."],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"id":"k_XKqVSHFmIN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632881376746,"user_tz":-540,"elapsed":369,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}},"outputId":"edcdf0a6-9bac-49ba-8804-f236cfef8360"},"source":["# print(pipeline_config)\n","pipeline_config.model.ssd.num_classes\n","pipeline_config.train_config.batch_size"],"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["128"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"lLqVd9ROUu98","executionInfo":{"status":"ok","timestamp":1632881557351,"user_tz":-540,"elapsed":310,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}},"outputId":"208d0f55-9e3c-4a0e-a4f4-dd3ecba43d96"},"source":["PRE_TRAINED_MODEL_PATH"],"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/pre_trained_model/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2UGy143VXDZH","executionInfo":{"status":"ok","timestamp":1632882150285,"user_tz":-540,"elapsed":311,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}},"outputId":"a0fb446f-6db4-4395-9601-bc1ec60096f9"},"source":["type(pipeline_config.train_input_reader.tf_record_input_reader.input_path)\n","# RepeatedScalarContainer - List구현체\n","type(pipeline_config.eval_input_reader) #RepeatedCompositeContainer: list 구현체"],"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["google.protobuf.pyext._message.RepeatedScalarContainer"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","metadata":{"id":"yDQK35T_FmIO","executionInfo":{"status":"ok","timestamp":1632882414806,"user_tz":-540,"elapsed":337,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}}},"source":["# 각 항목(속성)들을 변경(수정)\n","# 검출할 class의 개수(A ~ Z: 26)\n","pipeline_config.model.ssd.num_classes = 26 \n","# batch_size\n","pipeline_config.train_config.batch_size = 8\n","# pretrained model의 weight(전이학습에서 초기 weight - 파일명(확장자뺀)까지 지정.)\n","pipeline_config.train_config.fine_tune_checkpoint = os.path.join(PRE_TRAINED_MODEL_PATH, 'checkpoint', 'ckpt-0')\n","# pretrained 모델이 어떤 작업을 위한 학습을 한 모델인지 지정. \n","pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\" #object detection: detection (model zoo- outputs: Boxes )\n","\n","# Train dataset 관련 설정\n","# label map 파일 경로\n","pipeline_config.train_input_reader.label_map_path = LABEL_MAP_FILE_PATH\n","# train tfrecord 파일 경로\n","pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(TF_RECORD_PATH, 'train.tfr')]\n","\n","# Evaluation Dataset 관련 설정\n","# label map 파일 경로\n","pipeline_config.eval_input_reader[0].label_map_path = LABEL_MAP_FILE_PATH\n","# valid tfrecord 경로\n","pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(TF_RECORD_PATH, 'valid.tfr')]"],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"id":"_krxfVVOY-Fx","executionInfo":{"status":"ok","timestamp":1632882808432,"user_tz":-540,"elapsed":329,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}}},"source":["# 변경된 내용을 pipeline.config 파일에 덮어쓰기\n","# TrainEvalPipelineConfig를 text(string)으로 변환\n","config_text = text_format.MessageToString(pipeline_config)\n","# 파일로 저장(출력)\n","with open(PIPELINE_CONFIG_PATH, 'w') as fw:\n","    fw.write(config_text)"],"execution_count":56,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Gy_7KQYY-BO"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m-TYLrKWY9-q"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R1dChcDEFmIO"},"source":["# Model 학습\n","- 다음 명령어를 실행한다.\n","- 시간이 오래 걸리므로 terminal에서 실행한다.\n","```\n","python models/research/object_detection/model_main_tf2.py --model_dir=workspace/model/checkpoint --pipeline_config_path=workspace/model/pipeline.config --num_train_steps=3000\n","```\n","\n","## 옵션\n","- model_dir: 학습한 모델의 checkpoint 파일을 저장할 경로. (1000 step당 저장한다.)\n","- pipeline_config_path: pipeline.config 파일 경로\n","- num_train_steps: 학습할 step 수"]},{"cell_type":"code","metadata":{"id":"AIozlc_DFmIP","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1632883905412,"user_tz":-540,"elapsed":318,"user":{"displayName":"Sunghwan KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06010856989212311727"}},"outputId":"e4727a68-ccaf-4824-9218-722880e16b50"},"source":["f\"!python models/research/object_detection/model_main_tf2.py  --model_dir {CHECK_POINT_PATH}  \\\n","--pipeline_config_path  {PIPELINE_CONFIG_PATH}  --num_train_steps=3000\""],"execution_count":59,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'!python models/research/object_detection/model_main_tf2.py  --model_dir /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/model/checkpoint  --pipeline_config_path  /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/model/pipeline.config  --num_train_steps=3000'"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","metadata":{"id":"2CW2oetjFmIQ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"03b15f0f-1397-4769-c170-de98493e6eb1"},"source":["!python models/research/object_detection/model_main_tf2.py  --model_dir /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/model/checkpoint  --pipeline_config_path  /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/model/pipeline.config  --num_train_steps=3000"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2021-09-29 02:52:22.598905: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","2021-09-29 02:52:22.598958: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (6aca4916ae49): /proc/driver/nvidia/version does not exist\n","WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n","W0929 02:52:22.600629 140206738900864 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n","INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n","I0929 02:52:22.603456 140206738900864 mirrored_strategy.py:369] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n","INFO:tensorflow:Maybe overwriting train_steps: 3000\n","I0929 02:52:22.609785 140206738900864 config_util.py:552] Maybe overwriting train_steps: 3000\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I0929 02:52:22.609966 140206738900864 config_util.py:552] Maybe overwriting use_bfloat16: False\n","WARNING:tensorflow:From /content/models/research/object_detection/model_lib_v2.py:558: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","W0929 02:52:22.750567 140206738900864 deprecation.py:345] From /content/models/research/object_detection/model_lib_v2.py:558: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","INFO:tensorflow:Reading unweighted datasets: ['/content/tfrecord/train.tfr']\n","I0929 02:52:22.780913 140206738900864 dataset_builder.py:163] Reading unweighted datasets: ['/content/tfrecord/train.tfr']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/tfrecord/train.tfr']\n","I0929 02:52:22.781211 140206738900864 dataset_builder.py:80] Reading record datasets for input file: ['/content/tfrecord/train.tfr']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0929 02:52:22.781337 140206738900864 dataset_builder.py:81] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0929 02:52:22.781448 140206738900864 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n","W0929 02:52:22.794500 140206738900864 deprecation.py:345] From /content/models/research/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n","WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0929 02:52:22.833943 140206738900864 deprecation.py:345] From /content/models/research/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W0929 02:52:31.142888 140206738900864 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","W0929 02:52:34.906947 140206738900864 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0929 02:52:36.880822 140206738900864 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","2021-09-29 02:52:39.591256: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","2021-09-29 02:52:39.948749: W tensorflow/core/framework/dataset.cc:679] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n","/usr/local/lib/python3.7/dist-packages/keras/backend.py:401: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:617: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","W0929 02:53:06.183000 140204597274368 deprecation.py:548] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:617: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n"]}]},{"cell_type":"markdown","metadata":{"id":"mdssqw2xFmIQ"},"source":["# 학습한 모델 추출(export)\n","- `models/research/object_detection/exporter_main_v2.py` 사용\n","- 옵션\n","    - `exporter_main_v2.py --helpshort || exporter_main_v2.py --helpfull`\n","    - input_type : input node type\n","        - image_tensor, encoded_image_string_tensor\n","    - train_checkpoint: 학습된 checkpoint 파일이 저장된 경로(folder/directory)\n","    - pipeline_config_path: pipeline.config 파일의 경로 (파일명 포함)\n","    - output_directory: export된 모델을 저장할 경로.\n","- 추출된 디렉토리 구조\n","```bash\n","output_dir\n","├─ checkpoint/\n","├─ saved_model/\n","└─ pipeline.config\n","```\n","    - checkpoint: custom data 학습한 checkpoint 파일들을 이 디렉토리로 복사한다.\n","    - save_model: pipeline.config 설정에 맞춰 생성된 model\n","    - pipeline.config: pipeline.config 설정파일"]},{"cell_type":"code","metadata":{"id":"NBDxDDvFFmIR"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GKtShy0LFmIS"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R48-qlLoFmIS"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_9knRnd6FmIT"},"source":["# Inference(추론)"]},{"cell_type":"markdown","metadata":{"id":"7UAV_LuxFmIU"},"source":["### 사용 함수,메소드\n","-  ### tf.convert_to_tensor(array_like, dtype)\n","    - array_like 를 Tensoflow Tensor 객체로 변환\n","    - `tf.convert_to_tensor([[1,2],[3,4]])`\n","- ### detection_model.preprocess(image 4차원 ndarray)\n","    - 전달받은 이미지를 model의 input shape에 맞게 resizing 한다.\n","    - 반환값: (resize된 image Tensor, 이미지의 shape) 을 tuple로 반환\n","- ### detection_model.predict(image tensor, image_shape tensor)\n","    - 추론/detection 메소드\n","    - 이미지와 image shape을 받아서 detection한 결과를 딕셔너리로 반환한다.\n","    - **반환 dictionary key**\n","        - **preprocessed_inputs**:  입력 이미지 Tensor. preprocess()로 처리된 이미지. \n","        - **feature_maps**: List. feature map 들을 반환\n","        - **anchors**: 2D Tensor. normalize 된 anchor box들의 좌표를 반환. 2-D float tensor: \\[num_anchors, 4\\]\n","        - **final_anchors**: 3D Tensor. batch 당 anchors. (anchors에 batch가 포함된 것). \\[batch_size, num_anchors, 4\\]\n","        - **box_encodings**: 3D float tensor. predict한 box들의 normalize된 좌표. \\[batch_size, num_anchors,box_code_dimension\\]\n","        - **class_predictions_with_background**: 3D Tensor. 클래스 확률을 반환.(logit). \\[batch_size, num_anchors, num_classes+1]\\\n","            - background 확률을 포함해서 num_classes+1개가 된다. (index 0: background)\n","            \n","- ### detection_model.postprocess(prediction_dict, shape)\n","    - predict()가 예측한 결과에서 **Non-Maxinum Suppression**을 실행해서 최종 Detection 결과를 반환한다.\n","        - predict()는 anchor별로 예측결과를 모아서 주고 post-process는 최종 결과를 추출해서 반환.\n","    - **반환 dictionary key**\n","        - **num_detections**: Detect한 개수 (bounding box 개수)\n","        - **detection_boxes**: [batch, max_detections, 4]. 후처리한 detection box\n","        - **detection_scores**: [batch, max_detections]. post-processed detection box들의 detection score들 (detection score는 box안에 물체가 있을 확률값 - confidence score).\n","        - **detection_classes**: [batch, max_detections] tensor with classes for post-processed detection classes.\n","        - **raw_detection_boxes**:[batch, total_detections, 4] Non-Max Suppression 하기 전의 감지된 box들\n","        - **raw_detection_scores**: [batch, total_detections, num_classes_with_background]. raw detection box들의 class별 점수\n","        - **detection_multiclass_scores**: [batch, max_detections, num_classes_with_background] post-processed이후 남은 bounding box 들의 class별 점수. LabelMap의 class에 background가 추가되어 계산된다.\n","        - **detection_anchor_indices**: [batch, max_detections] post-processed 이후 나은 anchor box의 index들."]},{"cell_type":"code","metadata":{"id":"IQJH7HiuFmIV"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6gkxzoDjFmIV"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PD_TkmADFmIW"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2RVS6lhgFmIW"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CDeYImc0FmIX"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q6wM4m-2FmIX"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Igtxn7B1FmIY"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DC89wPxVFmIa"},"source":["# 새로운 이미지 Detection"]},{"cell_type":"code","metadata":{"id":"SC_w0h_qFmIi"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TqqmMUF7FmIj"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s944g3nEFmIk"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h8-z3ZrsFmIk"},"source":[""],"execution_count":null,"outputs":[]}]}